---
title: "Lab 1: COVID-19"
author: 
  name: "Doug Dunn"
  email: dunnd@colostate.edu 
format: html
editor: visual
---

```{r}
library(tidyverse)
library(flextable)
library(dplyr)
library(zoo)
library(patchwork)
library(scales)
library(broom)
```

# #1 Daily Summary

## a.

```{r}
data <- read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')
```

## b. and c.

```{r}
my.date <- as.Date("2022-02-01")
my.state <- "Colorado"
```

## d.

```{r}
co_data <- data %>% 
  filter(state == my.state) %>% 
  group_by(county) %>% 
  mutate(new_cases = cases - lag(cases),
         new_deaths = deaths - lag(deaths)) %>% 
  ungroup()
```

```{r}
today_data <- co_data %>% 
  filter(date == my.date)

```

## f.

```{r}
slice_max(today_data, n = 5, order_by = cases) %>% 
  select(county, state, cases) %>% 
  flextable() %>% 
  set_caption("Top 5 Counties by Cases")
```

```{r}
slice_max(today_data, n = 5, order_by = new_cases) %>% 
  select(county, state, new_cases) %>% 
  flextable() %>% 
  set_caption("Top 5 Counties by New Cases")
```

## #2 Evaluating Census Data

## a.

```{r}
pop_url <- 'https://www2.census.gov/programs-surveys/popest/datasets/2020-2023/counties/totals/co-est2023-alldata.csv'

```

```{r}
census_data <- read.csv(pop_url)
```

```{r}
fip_data <- census_data %>% 
  filter(COUNTY != 0) %>% 
  mutate(fips = sprintf("%02d%03d", 
                        as.numeric(STATE), 
                        as.numeric(COUNTY))) %>% 
  select(matches("Name|2021|fips"))
```

## b.

```{r}
glimpse(fip_data)
colnames(fip_data)
```

This data has rows for the names of the state and county, their 2021 population statistics (like estimated total, change, births, deaths, etc), and population change statistics from natural changes and migration. It also contains a FIP variable column that I created. There are 3144 rows, representing 3144 countries in the United States. This new data set has the following columns that match column in the "today_data" covid subset that I created earlier: "fips", "county", and "state".

# #3 Per Capita Summary

```{r}
todaypc_data <- today_data %>% 
  left_join(fip_data, join_by(fips)) %>% 
  mutate(pc_total = cases / POPESTIMATE2021) %>% 
  mutate(pc_new_cases = new_cases / POPESTIMATE2021) %>% 
  mutate(pc_new_deaths = new_deaths / POPESTIMATE2021)
```

```{r}
slice_max(todaypc_data, n = 5, order_by = pc_total) %>% 
  select(county, state, pc_total) %>% 
  flextable() %>% 
  set_caption("Top 5 Counties by Cases per Capita") %>% 
  colformat_double(j = "pc_total", digits = 2) %>% 
  set_header_labels(county = "County",
                    state = "State",
                    pc_total = "Cases per Capita")
```

```{r}
todaypc_data <- todaypc_data %>% 
  mutate(pc_new_cases_thsnd = pc_new_cases * 1000)

slice_max(todaypc_data, n = 5, order_by = pc_new_cases) %>% 
  select(county, state, pc_new_cases_thsnd) %>% 
  flextable() %>% 
  set_caption("Top 5 Counties by New Cases per Capita") %>% 
  colformat_double(j = "pc_new_cases_thsnd", digits = 2) %>% 
  set_header_labels(county = "County",
                    state = "State",
                    pc_new_cases_thsnd = "New Cases per 1000")
```

# #4 Rolling Thresholds

```{r}
twoweek_data <- co_data %>% 
  filter(date >= my.date - 14 & date <= my.date) %>% 
  left_join(fip_data, join_by(fips)) %>% 
  mutate(pc_new_cases = new_cases / POPESTIMATE2021)

twoweek_cases <- twoweek_data %>%   
  group_by(county) %>% 
  summarise(tw_cases = ((sum(pc_new_cases)))) %>% 
  mutate(tw_cases_hthsnd = tw_cases * 100000)

watchlist <- twoweek_cases %>%   
  filter(tw_cases_hthsnd >= 100)

```

```{r}
slice_max(twoweek_cases, n = 5, order_by = tw_cases_hthsnd) %>% 
  select(county, tw_cases_hthsnd) %>% 
  flextable() %>% 
  set_caption("Top 5 Counties by New Cases 
              in the last two weeks") %>% 
  colformat_double(j = "tw_cases_hthsnd", digits = 0) %>% 
  set_header_labels(county = "County",
                    tw_cases_hthsnd = "New Cases per 100,000")
```

```{r}
print(paste0("Number of Counties that meet watchlist conditions: ",
             nrow(watchlist)))

```

# #5 Death toll

```{r}
yearly_deaths <- co_data %>%
  left_join(fip_data, join_by(fips)) %>% 
  mutate(year = year(date)) %>% 
  filter(year == 2021) %>% 
  group_by(county) %>% 
  summarise(total_c19_deaths = sum(new_deaths),
            POPESTIMATE2021 = first(POPESTIMATE2021),
            DEATHS2021 = first(DEATHS2021)
            ) %>% 
  mutate(percent_deaths = (total_c19_deaths / 
                          DEATHS2021)*100)
```

```{r}
twentypercent_counties <- yearly_deaths %>% 
  filter(percent_deaths >= 20)
```

```{r}
ggplot(twentypercent_counties, aes(x = county, y = percent_deaths)) +
  geom_col() +
  labs(
    x = "County",
    y = "% Deaths",
    title = "COVID Deaths as % of Total Deaths in 2021",
    subtitle = "For Counties with greater than 20% COVID Deaths of Total Deaths"
  ) + 
  theme_classic() +
  theme(axis.text = element_text(angle = 90, hjust = 1))
```

# #6 Multi-state

## a.

```{r}
states_of_interest <- c("New York", "Colorado", "Alabama", "Ohio")
```

```{r}
fourstates_data <- data %>% 
  filter(state == states_of_interest,) %>% 
  group_by(state, county) %>% 
  mutate(new_cases = cases - lag(cases),
         new_deaths = deaths - lag(deaths)) %>% 
  ungroup()


```

```{r}
sum_fourstates_data <- fourstates_data %>% 
  group_by(state, date) %>% 
    summarise(total_cases = sum(cases, na.rm = TRUE),
              total_new_cases = sum(new_cases, na.rm = TRUE)) %>% 
  mutate(rm_cases = rollmean(x = total_new_cases, k = 7, fill = NA))
```

## b.

```{r}
ggplot(sum_fourstates_data, aes(x = date)) +
  geom_point(aes(y = total_new_cases)) +
  geom_line(aes(y = rm_cases), color = "red", size = 2.0) +
  facet_wrap(~ state, scales = "free_y") +
  labs(title = "Total New Cases by State",
       x = "Date",
       y = "Total New Cases")
  
```

## c.

```{r}
state_census_data <- census_data %>% 
  filter(COUNTY == 0) %>% 
  filter(STNAME %in% states_of_interest) %>%
  rename(state = STNAME)

```

```{r}
capita_fourstates_data <- sum_fourstates_data %>% 
  group_by(state) %>% 
    left_join(state_census_data, join_by(state)) %>% 
  ungroup() %>% 
  mutate(current_year = year(date)) %>% 
  mutate(current_population = case_when(
          current_year == 2020 ~ POPESTIMATE2020,
          current_year == 2021 ~ POPESTIMATE2021,
          current_year == 2022 ~ POPESTIMATE2022
  )) %>% 
  mutate(pc_new_cases = total_new_cases / current_population) %>% 
  mutate(pc_rm_cases = rollmean(x = pc_new_cases, 
                                k = 7, fill = NA)) %>%
  mutate(hthsnd_pc_rm_cases = pc_rm_cases * 100000)
 
```

## d.

```{r}
ggplot(capita_fourstates_data, aes(x =date, y = hthsnd_pc_rm_cases, color = state)) +
  geom_line(size = 1) +
  scale_x_date(breaks = as.Date(c("2020-01-01", "2020-07-01", 
                                  "2021-01-01", "2021-07-01", 
                                  "2022-01-01"))) +
  scale_color_manual(name = "State",
                     values = c("Alabama" = "red", 
                                "Colorado" = "green", 
                                "Ohio" = "blue", 
                                "New York" = "black")) + 
  labs(title = "7 Day Rolling Mean of New Cases per Capita",
       x = "Date",
       y = "7 Day Rolling Mean of New Cases per 100,000") +
  theme_minimal() +
  theme(axis.text = element_text(angle = 90, hjust = 1))
```

## e.

Scaling the population demonstrated that the 4 states experienced some similar peaks and trends in their cases relative to their population. This would indicate that they were experiencing similar rates of transmission, and that their population total was the controlling factor in the total number of new cases. It also shows that Alabama experienced either their own spike in cases, or perhaps a delay in the spike of new cases (indicated by a lack of travel?). New York also demonstrates that, even when corrected for population, they had a massive spike in new cases at the end of the pandemic. Although this spike was at the same time as other states, it is proportionally much larger. New York also experienced a very early on spike in cases.

# #7

```{r}
loc_url <- 'https://raw.githubusercontent.com/mikejohnson51/csu-ess-330/refs/heads/main/resources/county-centroids.csv'
```

```{r}
loc_data <- read.csv(loc_url) %>% 
  mutate(fips = sprintf("%05d", fips))
```

```{r}
covid_data_loc <- data %>% 
  left_join(loc_data, join_by(fips))
  
```

```{r}
covid_daily_loc <- covid_data_loc %>%
  filter(!is.na(LON) & ! is.na(LAT)) %>%
  mutate(deaths = replace(deaths, is.na(deaths), 0)) %>% 
  group_by(date) %>% 
    summarise(
      cases_wtmean_x = weighted.mean(LON, cases, na.rm = TRUE),
      cases_wtmean_y = weighted.mean(LAT, cases, na.rm = TRUE),
      deaths_wtmean_x = weighted.mean(LON, deaths, na.rm = TRUE),
      deaths_wtmean_y = weighted.mean(LAT, deaths, na.rm = TRUE),
      total_cases = sum(cases),
      total_deaths = sum(deaths)
            ) %>% 
  ungroup()
```

```{r}
# Plot 1: Weighted mean center for cases (navy)
plot_cases <- ggplot(covid_daily_loc, 
                     aes(x = cases_wtmean_x, 
                         y = cases_wtmean_y, 
                         size = total_cases)) +
  borders("state", fill = "gray90", colour = "white") +
  geom_point(color = "navy") +
  scale_size(range = c(1, 10), 
             name = "Total Cases", 
             labels = comma_format()) +
  labs(title = "Cases", x = NULL, y = NULL) +
  theme_minimal()

# Plot 2: Weighted mean center for deaths (red)
plot_deaths <- ggplot(covid_daily_loc, 
                      aes(x = deaths_wtmean_x, 
                          y = deaths_wtmean_y, 
                          size = total_deaths)) +
  borders("state", fill = "gray90", colour = "white") +
  geom_point(color = "red") +
  scale_size(range = c(1, 10), 
             name = "Total Cases", 
             labels = comma_format()) +
  labs(title = "Deaths", x = NULL, y = NULL) +
  theme_minimal()

# Combine plots side by side using patchwork
combined_plot <- plot_cases + plot_deaths

# Display the combined plot
combined_plot + plot_annotation(
  title = 'COVID Deaths and Cases',
  subtitle = 'Weighted mean center calculated from County-level data'
)
```

Both plots shows the "start" of the cases and deaths as being around Seattle. The initial cases had a bit more of a sporadic spread as it moved east, with the center bouncing around a bit. The cases then solidly rested in the mid-Atlantic region and shifted south and west to center on southern Missouri. Deaths had a more linear initial spread, tracing a trail southeast, again to the mid-Atlantic, before also centering on southern Missouri.

# #8 Trends

## Data Preparation

## a.

```{r}
county_census_data <- census_data %>% 
  filter(!COUNTY == 0) %>% 
  mutate(fips = sprintf("%02d%03d", 
                        as.numeric(STATE), 
                        as.numeric(COUNTY)))
```

```{r}
covid_trends <- data %>%
  group_by(state, county) %>% 
  mutate(new_cases = cases - lag(cases),
         new_deaths = deaths - lag(deaths))
```

```{r}
covid_trends <- covid_trends %>% 
  left_join(county_census_data, join_by(fips))
```

## b.

```{r}
covid_trends <- covid_trends %>% 
  mutate(
    year = year(date),
    month = month(date),
    season = case_when(
      month >= 3 & month <=5 ~ "Spring",
      month >= 6 & month <=8 ~ "Summer",
      month >= 9 & month <=11 ~ "Fall",
      month == 12 | month == 1 | month == 2 ~ "Winter"
    )
  )
```

## c.

```{r}
covid_trends <- covid_trends %>% 
  mutate(current_population = case_when(
          year == 2020 ~ POPESTIMATE2020,
          year == 2021 ~ POPESTIMATE2021,
          year == 2022 ~ POPESTIMATE2022))
```

```{r}
covid_summary <- covid_trends %>%
  group_by(state, year, season) %>%
  summarize(
    total_population = sum(current_population, na.rm = TRUE),  
    total_new_cases = sum(new_cases, na.rm = TRUE),
    total_new_deaths = sum(new_deaths, na.rm = TRUE),
    .groups = "drop"
  )
```

## d.

```{r}
covid_summary <- covid_summary %>%
  mutate(total_new_cases = if_else(total_new_cases < 0, 
                                   0, total_new_cases),
         total_new_deaths = if_else(total_new_deaths < 0, 
                                    0, total_new_deaths))

```

```{r}
log_covid_summary <- covid_summary %>% 
  mutate(log_total_pop = log(total_population + 1),
         log_total_new_cases = log(total_new_cases + 1),
         log_total_new_deaths = log(total_new_deaths + 1))
```

## Model Building

## a.

```{r}
model <- lm(log_total_new_cases ~ log_total_new_deaths * log_total_pop + season, 
            data = log_covid_summary)

summary(model)

```

```{r}
# Extract key statistics
model_summary <- summary(model)
r_squared <- model_summary$r.squared
adj_r_squared <- model_summary$adj.r.squared

# Create Coefficient table
coef_table <- as.data.frame(coef(model_summary))
colnames(coef_table) <- c("Estimate", "Std. Error", "t value", "P-value")
coef_table$`P-value` <- format(coef_table$`P-value`, 
                               scientific = TRUE, digits = 3)
coef_table$Coefficient <- rownames(coef_table)
rownames(coef_table) <- NULL
coef_table <- coef_table[, c("Coefficient", "Estimate", "Std. Error", "t value", "P-value")]

# Compute the overall model p-value using an ANOVA F-test
model_p_value <- pf(model_summary$fstatistic[1], 
                    model_summary$fstatistic[2], 
                    model_summary$fstatistic[3], 
                    lower.tail = FALSE)

# Create a data frame for the table
model_stats <- data.frame(
  Metric = c("R-squared", "Adjusted R-squared", "Model p-value"),
  Value = c(round(r_squared, digits = 2), 
            round(adj_r_squared, digits = 2), 
            format(model_p_value, scientific = TRUE)
  )
)
```

```{r}
flextable(model_stats) %>%
  set_caption("Model Performance Metrics") %>% 
  autofit()

```

```{r}
flextable(coef_table) %>% 
  set_caption("Model Coefficients") %>% 
  colformat_double(digits = 3, big.mark = "") %>% 
  autofit()
  
```

The p-value indicates that their is very strong evidence for a statistically significant relationship between the log of new deaths and the log of new cases, so new deaths is a good metric for estimating new cases. Seasonally, there are more cases in Fall and Winter, and fewer in Spring and Summer. There is also a dampening effect of population, where larger populations have slightly few cases. The r-squared value indicates that this model has a strong fit for matching the distribution of log new deaths vs. log new cases. Overall this model would be a good use for estimating new cases based on the reported number of new deaths.

# #9 Evaluation

## a.

```{r}
augmented_data <- augment(model, data = log_covid_summary)

head(augmented_data)
```

## b.

```{r}
ggplot(data = augmented_data, 
       aes(x = log_total_new_cases,
           y = .fitted)) +
  geom_point(aes(color = season), 
             size = 2.5, alpha = 0.7, shape = 16) +
  geom_smooth(method = "lm", color = "black", size = 1, 
              linetype = "solid", se = FALSE) + 
  geom_abline(color = "blue") +
  scale_color_manual(values = c("Fall" = "darkred", 
                                "Spring" = "cyan", 
                                "Summer" = "yellow", 
                                "Winter" = "grey"),
                                name = "Season") +
  scale_x_continuous(name = "Observed Log New Cases")+
  scale_y_continuous(name = "Predicted Log New Cases") +
  annotate("text", x = Inf, y = -Inf, 
           label = paste0("R^2 = ", r_squared), 
           hjust = 1.1, vjust = -0.5, size = 5, 
           fontface = "bold", color = "black") +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(face = "bold"),
    axis.text = element_text(color = "black"),
    legend.position = "top",
    legend.title = element_text(face = "bold"),
    panel.grid.major = element_line(color = "gray90"),
    panel.grid.minor = element_blank()
  ) +
  labs(
    title = "Predicted vs. Actual Log of Total New Cases",
    subtitle = "Linear Regression Model with Seasonal Effects",
    caption = "Black line: Fit of predicted vs. actual"
    
  )
```

Overall the model looks pretty good, and there seems to be general linear relationship between the log of observed new cases and the log of predicted new cases. There are a few instances where the model seems to be significantly under predicting, but those are likely unique outliers. I would be happy to use this model to predict new cases.

## c.

```{r}
ggplot(augmented_data, aes(x = .resid)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "#4CAF50", 
                 color = "black", alpha = 0.85) +
  scale_x_continuous(name = "Residuals (Log Scale)", ) +
  scale_y_continuous(name = "Density") +
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", 
                              size = 16, color = "black"),
    plot.subtitle = element_text(hjust = 0.5, size = 12,
                                 color = "gray30"),
    axis.title = element_text(face = "bold", size = 12),
    axis.text = element_text(color = "black", size = 10),
    panel.grid.major = element_line(color = "gray85", size = 0.3),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "black", size = 0.5),
    plot.background = element_rect(fill = "white", color = NA)
        ) +
  labs(
    title = "Histogram of Residuals",
    subtitle = "Checking Normality for Linear Model Fit",
  )
```

The distribution of residuals on a log scale seems to be normal and follow a rough bell shape curve centered near zero. This would indicate that the residuals are equally distributed both above and below (over and under predictions) our linear model line. This distribution would indicate that the linear model was the appropriate model for this case.
